{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install openai streamlit chromadb pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import chromadb\n",
    "import base64\n",
    "import io\n",
    "import streamlit as st\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI API key (Set this properly in your environment)\n",
    "OpenAI_client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ChromaDB\n",
    "chroma_client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "try:\n",
    "    chroma_client.delete_collection(name=\"pdf_content\")\n",
    "except:\n",
    "    pass\n",
    "collection = chroma_client.create_collection(name=\"pdf_content\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image(image):\n",
    "    \"\"\"Convert image to base64 for OpenAI Vision API.\"\"\"\n",
    "    return base64.b64encode(image.getvalue()).decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_image(image):\n",
    "    \"\"\"Send image to OpenAI GPT-4o-Mini for description.\"\"\"\n",
    "    base64_image = encode_image(image)\n",
    "    response = OpenAI_client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Describe the attached image in JSON format.\"},\n",
    "            {\"role\": \"user\", \"content\": [{\"type\": \"image\", \"image\": base64_image}]}\n",
    "        ],\n",
    "    )\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_pdf(pdf_path):\n",
    "    \"\"\"Extract text and replace images with descriptions in-line.\"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    parsed_content = []\n",
    "\n",
    "    for page_num, page in enumerate(doc):\n",
    "        blocks = page.get_text(\"blocks\")  # Extract text blocks (for positioning)\n",
    "        images = page.get_images(full=True)  # Get images\n",
    "\n",
    "        content_blocks = []  # To store ordered content (text + images)\n",
    "\n",
    "        # Process text blocks first\n",
    "        for block in blocks:\n",
    "            block_text = block[4].strip()\n",
    "            if block_text:\n",
    "                content_blocks.append((block[1], \"text\", block_text))  # (y-position, type, content)\n",
    "\n",
    "        # Process images\n",
    "        for img_index, img in enumerate(images):\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "            image = io.BytesIO(image_bytes)\n",
    "\n",
    "            # Get image description\n",
    "            description = describe_image(image)\n",
    "            content_blocks.append((img[1], \"image\", f\"[Page: {page_num+1}, Image {img_index+1}]: {description}\"))\n",
    "\n",
    "        # Sort all content (text + images) by y-coordinate to maintain order\n",
    "        content_blocks.sort(key=lambda x: x[0])\n",
    "\n",
    "        # Construct final content with images in correct places\n",
    "        for block in content_blocks:\n",
    "            parsed_content.append(block[2])\n",
    "    return parsed_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_in_vector_db(doc_id, content):\n",
    "    \"\"\"Store parsed content in ChromaDB.\"\"\"\n",
    "    collection.add(documents=content, ids=[f\"{doc_id}_{i}\" for i in range(len(content))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_vector_db(query_text):\n",
    "    \"\"\"Query ChromaDB for relevant content.\"\"\"\n",
    "    results = collection.query(query_texts=[query_text], n_results=10)\n",
    "    return results[\"documents\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Usage\n",
    "pdf_path = \"/content.pdf\"\n",
    "parsed_content = parse_pdf(pdf_path)\n",
    "store_in_vector_db(\"content.pdf\", parsed_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query Example\n",
    "query_result = query_vector_db(\"What is ML?\")\n",
    "print(query_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
